{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be260096-2e24-4aac-b33f-26ed2b0bd3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. ... 0. 1. 1.]\n",
      " [0. 1. 0. ... 0. 1. 1.]\n",
      " [1. 0. 0. ... 0. 1. 1.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 1.]\n",
      " [0. 1. 0. ... 0. 0. 1.]\n",
      " [1. 0. 0. ... 1. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "client = MongoClient(\"mongodb+srv://saisharanyasriramoju05:Sharanya032005@cluster0.7fmgr.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\")\n",
    "\n",
    "db = client[\"hotel_guests\"]\n",
    "\n",
    "collection = db[\"dining_info\"]\n",
    "\n",
    "df_from_mongo = pd.DataFrame(list(collection.find()))\n",
    "\n",
    "df = df_from_mongo.copy()\n",
    "\n",
    "# Convert to date-time format\n",
    "\n",
    "df['check_in_date'] = pd.to_datetime(df['check_in_date'])\n",
    "df['check_out_date'] = pd.to_datetime(df['check_out_date'])\n",
    "df['order_time'] = pd.to_datetime(df['order_time'])\n",
    "\n",
    "# extract day, month, week etc from check_in and check_out dates\n",
    "\n",
    "df['check_in_day'] = df['check_in_date'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "df['check_out_day'] = df['check_out_date'].dt.dayofweek\n",
    "df['check_in_month'] = df['check_in_date'].dt.month\n",
    "df['check_out_month'] = df['check_out_date'].dt.month\n",
    "df['stay_duration'] = (df['check_out_date'] - df['check_in_date']).dt.days\n",
    "\n",
    "df[['booked_through_points','price_for_1']].groupby('booked_through_points').mean()\n",
    "# features that i want to derive based on historical customer trends\n",
    "features_df = df[df['order_time']<'2024-01-01']\n",
    "\n",
    "train_df = df[(df['order_time']>='2024-01-01')&(df['order_time']<='2024-10-01')]\n",
    "\n",
    "test_df = df[(df['order_time']>'2024-10-01')] # - pseudo prediction dataset\n",
    "\n",
    "customer_features = features_df.groupby('customer_id').agg(\n",
    "    total_orders_per_customer=('transaction_id', 'count'),\n",
    "    avg_spend_per_customer=('price_for_1', 'mean'),\n",
    "    avg_stay_duration=('stay_duration', 'mean'),\n",
    "    most_frequent_checkin_month=('check_in_month', lambda x: x.mode()[0]),\n",
    "    peak_dining_hour_per_customer=('order_time', lambda x: x.dt.hour.mode()[0])\n",
    ").reset_index()\n",
    "# create some more features (atleast 2 more)\n",
    "customer_features.to_excel('customer_features.xlsx',index=False)\n",
    "# Get most frequent cuisine & dish per customer\n",
    "customer_dish = features_df.groupby('customer_id').agg(\n",
    "    most_frequent_dish=('dish', lambda x: x.mode()[0])\n",
    ").reset_index()\n",
    "# Create atleast 1 more similar feature to the above\n",
    "customer_dish.to_excel('customer_dish.xlsx',index=False)\n",
    "# ðŸŒŸ Cuisine-Level Aggregations - Stats of customers preferring a specific cuisine\n",
    "cuisine_features = features_df.groupby('Preferred Cusine').agg(\n",
    "    total_orders_per_cuisine=('transaction_id', 'count'),\n",
    "    avg_spend_per_cuisine=('price_for_1', 'mean'),\n",
    "    most_frequent_order_hour_per_cuisine=('order_time', lambda x: x.dt.hour.mode()[0])\n",
    ").reset_index()\n",
    "# create some more features (atleast 1 more)\n",
    "cuisine_features.to_excel('cuisine_features.xlsx',index=False)\n",
    "# Most popular dish per cuisine\n",
    "cuisine_dish = features_df.groupby('Preferred Cusine').agg(\n",
    "    cuisine_popular_dish=('dish', lambda x: x.mode()[0])\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "cuisine_dish.to_excel('cuisine_dish.xlsx',index=False)\n",
    "\n",
    "# Create one more similar feature\n",
    "\n",
    "\n",
    "# Merge created features to train_df\n",
    "\n",
    "# merge 'on' what you are grouping by in above feature level dataframes you have created\n",
    "\n",
    "train_df = train_df.merge(customer_features, on='customer_id', how='left')\n",
    "train_df = train_df.merge(customer_dish.rename(columns={'dish': 'fav_dish_per_customer'}), on='customer_id', how='left')\n",
    "train_df = train_df.merge(cuisine_features, on='Preferred Cusine', how='left')\n",
    "train_df = train_df.merge(cuisine_dish, on='Preferred Cusine', how='left')\n",
    "\n",
    "\n",
    "train_df.drop(['_id','transaction_id','customer_id','price_for_1',\n",
    "               'Qty','order_time','check_in_date','check_out_date'],axis=1,inplace=True)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Select categorical columns for one-hot encoding\n",
    "categorical_cols = ['Preferred Cusine','most_frequent_dish','cuisine_popular_dish']\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# Apply transformation\n",
    "encoded_array = encoder.fit_transform(train_df[categorical_cols])\n",
    "print(encoded_array)\n",
    "# Convert to DataFrame\n",
    "encoded_df = pd.DataFrame(encoded_array, columns=encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Store the encoder\n",
    "joblib.dump(encoder, 'encoder.pkl')\n",
    "\n",
    "# Load the encoder when needed\n",
    "loaded_encoder = joblib.load('encoder.pkl')\n",
    "\n",
    "\n",
    "# Concatenate with the original DataFrame\n",
    "train_df = pd.concat([train_df.drop(columns=categorical_cols), encoded_df], axis=1)\n",
    "# Fit OneHotEncoder only on train set\n",
    "\n",
    "train_df.columns\n",
    "\n",
    "test_df = test_df.merge(customer_features, on='customer_id', how='left')\n",
    "test_df = test_df.merge(customer_dish.rename(columns={'dish': 'fav_dish_per_customer'}), on='customer_id', how='left')\n",
    "test_df = test_df.merge(cuisine_features, on='Preferred Cusine', how='left')\n",
    "test_df = test_df.merge(cuisine_dish, on='Preferred Cusine', how='left')\n",
    "\n",
    "test_df.drop(['_id','transaction_id','customer_id','price_for_1',\n",
    "               'Qty','order_time','check_in_date','check_out_date'],axis=1,inplace=True)\n",
    "\n",
    "encoded_test = encoder.transform(test_df[categorical_cols])\n",
    "\n",
    "# Convert to DataFrame\n",
    "encoded_test_df = pd.DataFrame(encoded_test, columns=encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "# Concatenate with test_df\n",
    "test_df = pd.concat([test_df.drop(columns=categorical_cols), encoded_test_df], axis=1)\n",
    "\n",
    "test_df\n",
    "\n",
    "train_df = train_df.dropna(subset=['dish'])\n",
    "\n",
    "# Encode the target column 'dish' using LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train_df['dish'] = label_encoder.fit_transform(train_df['dish'])\n",
    "\n",
    "# Split into features (X) and target (y)\n",
    "X_train = train_df.drop(columns=['dish'])  # Features\n",
    "y_train = train_df['dish']\n",
    "\n",
    "test_df = test_df.dropna(subset=['dish'])\n",
    "\n",
    "# Encode 'dish' using the SAME LabelEncoder from training\n",
    "test_df['dish'] = label_encoder.transform(test_df['dish']) \n",
    "\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "X_test = test_df.drop(columns=['dish'])  # Features\n",
    "y_test = test_df['dish']\n",
    "\n",
    "# You need to achieve an accuracy of atleast 0.19 if you have replicated the same features in this code. \n",
    "# Else, you should have created your own features and achieve an accuracy of more than 0.15\n",
    "\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    objective=\"multi:softmax\",  # Multi-class classification\n",
    "    eval_metric=\"mlogloss\",  # Multi-class log loss\n",
    "    learning_rate=0.1, # experiment with different values\n",
    "    max_depth=1,\n",
    "    n_estimators=100,\n",
    "    subsample=1,\n",
    "    colsample_bytree=1,\n",
    "    random_state=50\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(xgb_model, 'xgb_model_dining.pkl')\n",
    "pd.DataFrame(X_train.columns).to_excel('features.xlsx')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a19509-eab7-4385-9d4d-d26129a847fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bb0d22-bb39-4d2a-93e7-a57a86d5e067",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
